{
    "model_name":"xlm-roberta-base",
    "epochs":4,
    "batch_size":16,
    "lm_lr":5e-5,
    "cls_lr":5e-4,
    "gradient_accumulation_steps":8
}