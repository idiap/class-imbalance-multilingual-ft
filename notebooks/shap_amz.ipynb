{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability of speech classification model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the `Partition` explainer for a multiclass text classification scenario. Once the SHAP values are computed for a set of sentences we then visualize feature attributions towards individual classes. The text classifcation model we use is BERT fine-tuned on an emotion dataset to classify a sentence among six classes: joy, sadness, anger, fear, love and surprise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import transformers\n",
    "import datasets\n",
    "import shap\n",
    "import seaborn  as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill this in\n",
    "PATH_TO_SHAP_BAL = \"\"\n",
    "PATH_TO_SHAP_IMBAL = \"\"\n",
    "PATH_TO_SHAP_IMBAL_CW = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_from_disk(\"../datasets/amz_reviews\")\n",
    "dataset = dataset[\"test\"]\n",
    "data = pd.DataFrame(\n",
    "    {\"text\": dataset[\"review_body\"], \"label\": dataset[\"stars\"], \"language\" : dataset[\"language\"]}\n",
    ")\n",
    "data = data.sample(4000, random_state=0)\n",
    "\n",
    "shap_values_bal = pickle.load(open(PATH_TO_SHAP_BAL,\"rb\"))\n",
    "shap_values_imbal = pickle.load(open(PATH_TO_SHAP_IMBAL,\"rb\"))\n",
    "shap_values_imbal_cw = pickle.load(open(PATH_TO_SHAP_IMBAL_CW,\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_bal = pd.DataFrame(\n",
    "    {\n",
    "        \"values\": shap_values_bal.values,\n",
    "        \"base_values\": list(shap_values_bal.base_values),\n",
    "        \"feature_names\": shap_values_bal.feature_names,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_shap_imbal = pd.DataFrame(\n",
    "    {\n",
    "        \"values\": shap_values_imbal.values,\n",
    "        \"base_values\": list(shap_values_imbal.base_values),\n",
    "        \"feature_names\": shap_values_imbal.feature_names,\n",
    "    }\n",
    ")\n",
    "\n",
    "df_shap_imbal_cw = pd.DataFrame(\n",
    "    {\n",
    "        \"values\": shap_values_imbal_cw.values,\n",
    "        \"base_values\": list(shap_values_imbal_cw.base_values),\n",
    "        \"feature_names\": shap_values_imbal_cw.feature_names,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_bal[\"overall_shap_values\"] = df_shap_bal.apply(lambda x : x[\"values\"].sum(axis=0) +x[\"base_values\"], axis=1)\n",
    "df_shap_imbal[\"overall_shap_values\"] = df_shap_imbal.apply(lambda x : x[\"values\"].sum(axis=0) +x[\"base_values\"], axis=1)\n",
    "df_shap_imbal_cw[\"overall_shap_values\"] = df_shap_imbal_cw.apply(lambda x : x[\"values\"].sum(axis=0) +x[\"base_values\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS TO GET PREDICTIONS DISTRIBUTIONS\n",
    "df_shap_bal_with_language = df_shap_imbal.copy()\n",
    "df_shap_bal_with_language[\"language\"] = data.reset_index()[\"language\"]\n",
    "df_shap_bal_with_language[\"predictions\"] = df_shap_bal_with_language[\"overall_shap_values\"].apply(lambda x: np.argmax(x))\n",
    "LANGUAGE_GROUP = {\"de\":0, \"en\": 0, \"zh\":0, \"fr\":1 , \"es\":1, \"ja\":1}\n",
    "df_shap_bal_with_language[\"language_group\"] = df_shap_bal_with_language[\"language\"].apply(lambda x: LANGUAGE_GROUP[x])\n",
    "# round to 1 decimal and multiply by 100\n",
    "# then format by assing percentage sign and & in between to be latex reads\n",
    "df_shap_bal_with_language.groupby(\"language_group\")[\"predictions\"].value_counts(normalize=True).apply(lambda x : round(x*100, 1)).apply(lambda x: str(x) + \"\\%\").unstack().apply(lambda x: \" & \".join(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_all = pd.concat([\n",
    "    df_shap_bal.add_suffix(\"_bal\"),\n",
    "    df_shap_imbal.add_suffix(\"_imbal\"),\n",
    "    df_shap_imbal_cw.add_suffix(\"_imbal_cw\"),\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_all[\"contribution_diff_per_token_imbal\"] = df_shap_all.apply(\n",
    "    lambda x: x[\"values_imbal\"] - x[\"values_bal\"]\n",
    "    ,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_shap_all[\"contribution_diff_per_token_imbal_cw\"] = df_shap_all.apply(\n",
    "    lambda x: x[\"values_imbal_cw\"] - x[\"values_bal\"]\n",
    "    ,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "threshold = 0.01\n",
    "\n",
    "df_shap_contrib_imbal = df_shap_all.apply(\n",
    "    lambda x: pd.Series(\n",
    "        dict(\n",
    "            [\n",
    "                (\n",
    "                    \"contribution_to_diff_from_neutral\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal\"],\n",
    "                        mask=~(np.abs(x[\"values_bal\"]) <= threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_positive\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal\"],\n",
    "                        mask=~(x[\"values_bal\"] > threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_negative\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal\"],\n",
    "                        mask=~(x[\"values_bal\"] < -threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_base_values\",\n",
    "                    x[\"base_values_imbal\"] - x[\"base_values_bal\"],\n",
    "                ),\n",
    "                (\"overall_shap_values_bal\", x[\"overall_shap_values_bal\"]),\n",
    "                (\"overall_shap_values_imbal\", x[\"overall_shap_values_imbal\"]),\n",
    "                (\"overall_shap_values_imbal_cw\", x[\"overall_shap_values_imbal_cw\"]),\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "df_shap_contrib_imbal_cw = df_shap_all.apply(\n",
    "    lambda x: pd.Series(\n",
    "        dict(\n",
    "            [\n",
    "                (\n",
    "                    \"contribution_to_diff_from_neutral\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal_cw\"],\n",
    "                        mask=~(np.abs(x[\"values_bal\"]) <= threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_positive\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal_cw\"],\n",
    "                        mask=~(x[\"values_bal\"] > threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_negative\",\n",
    "                    np.ma.array(\n",
    "                        x[\"contribution_diff_per_token_imbal_cw\"],\n",
    "                        mask=~(x[\"values_bal\"] < -threshold),\n",
    "                    ).sum(axis=0),\n",
    "                ),\n",
    "                (\n",
    "                    \"contribution_to_diff_from_base_values\",\n",
    "                    x[\"base_values_imbal_cw\"] - x[\"base_values_bal\"],\n",
    "                ),\n",
    "                (\"overall_shap_values_bal\", x[\"overall_shap_values_bal\"]),\n",
    "                (\"overall_shap_values_imbal\", x[\"overall_shap_values_imbal\"]),\n",
    "                (\"overall_shap_values_imbal_cw\", x[\"overall_shap_values_imbal_cw\"]),\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap_contrib_imbal[\"language\"] = data[\"language\"].reset_index(drop=True)\n",
    "df_shap_contrib_imbal_cw[\"language\"] = data[\"language\"].reset_index(drop=True)\n",
    "\n",
    "df_shap_contrib_langavg_imbal = (df_shap_contrib_imbal.groupby(\"language\")\n",
    "    .apply(lambda df: df.apply(lambda x: np.ma.vstack(x).mean(axis=0), axis=0))\n",
    "    .rename_axis([\"language\",\"label\"])\n",
    "    .reset_index())\n",
    "\n",
    "df_shap_contrib_langavg_imbal_cw = (df_shap_contrib_imbal_cw.groupby(\"language\")\n",
    "    .apply(lambda df: df.apply(lambda x: np.ma.vstack(x).mean(axis=0), axis=0))\n",
    "    .rename_axis([\"language\",\"label\"])\n",
    "    .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    data=(\n",
    "        df_shap_contrib_langavg_imbal.query(\"label==4\")\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"contribution_to_diff_from_neutral\": \"from_neutral\",\n",
    "                \"contribution_to_diff_from_positive\": \"from_positive\",\n",
    "                \"contribution_to_diff_from_negative\": \"from_negative\",\n",
    "                \"contribution_to_diff_from_base_values\": \"from_base_values\",\n",
    "            }\n",
    "        )\n",
    "        .melt(\n",
    "            id_vars=[\"language\", \"label\"],\n",
    "            value_vars=[\n",
    "                \"from_neutral\",\n",
    "                \"from_positive\",\n",
    "                \"from_negative\",\n",
    "                \"from_base_values\",\n",
    "            ],\n",
    "            var_name=\"contribution_type\",\n",
    "            value_name=\"contribution\",\n",
    "        )\n",
    "    ),\n",
    "    x=\"contribution\",\n",
    "    y=\"contribution_type\",\n",
    "    hue=\"language\",\n",
    "    hue_order=[\"en\", \"de\", \"zh\", \"fr\", \"es\", \"ja\"],\n",
    ")\n",
    "\n",
    "plt.xlim(-0.16, 0.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    data=(\n",
    "        df_shap_contrib_langavg_imbal_cw.query(\"label==4\")\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"contribution_to_diff_from_neutral\": \"from_neutral\",\n",
    "                \"contribution_to_diff_from_positive\": \"from_positive\",\n",
    "                \"contribution_to_diff_from_negative\": \"from_negative\",\n",
    "                \"contribution_to_diff_from_base_values\": \"from_base_values\",\n",
    "            }\n",
    "        )\n",
    "        .melt(\n",
    "            id_vars=[\"language\", \"label\"],\n",
    "            value_vars=[\n",
    "                \"from_neutral\",\n",
    "                \"from_positive\",\n",
    "                \"from_negative\",\n",
    "                \"from_base_values\",\n",
    "            ],\n",
    "            var_name=\"contribution_type\",\n",
    "            value_name=\"contribution\",\n",
    "        )\n",
    "    ),\n",
    "    x=\"contribution\",\n",
    "    y=\"contribution_type\",\n",
    "    hue=\"language\",\n",
    "    hue_order=[\"en\", \"de\", \"zh\", \"fr\", \"es\", \"ja\"],\n",
    ")\n",
    "\n",
    "plt.xlim(-0.16, 0.16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
